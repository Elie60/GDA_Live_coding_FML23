{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g17Z46tmw2oZ"
   },
   "source": [
    "# GDA Implementation.\n",
    "\n",
    "Implement the Gaussian Discriminant Analysis (GDA) learning algorithm following the steps as discussed in class.\n",
    "\n",
    "INSTRUCTION: Rename your notebook as: <br>\n",
    "`firstName_LastName_Live_coding_GDA.ipynb`.\n",
    "\n",
    "Notes: \n",
    "* Do not use any built-in functions to complete a task;\n",
    "* Do not import additional libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "id": "aT5nlL-QTKwv"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_-lL4Yq9Tbzn",
    "outputId": "30937363-7f7e-4360-e123-b4cdb1ebe441"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Generate data\n",
    "def generate_data():\n",
    "  x, y = make_classification(n_samples= 1000, n_features=3, n_redundant=0, \n",
    "                           n_informative=3, random_state=1, \n",
    "                           n_clusters_per_class=1)\n",
    "  \n",
    "  return x,y\n",
    "\n",
    "x,y= generate_data()\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -0.42600458,  0.3092346 ,  1.13238592],\n",
       "       [ 0.        ,  0.23750039,  0.85236655,  1.27032566],\n",
       "       [ 1.        , -1.50956177,  0.57932947, -0.58204952],\n",
       "       ...,\n",
       "       [ 1.        ,  0.38796174,  1.01606996, -1.499496  ],\n",
       "       [ 1.        , -0.74578403,  1.56454128, -1.05700466],\n",
       "       [ 0.        ,  1.08716336, -0.29150009,  0.98548405]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=np.column_stack((y,x))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -1.94487899,  0.66319866, -3.11399407],\n",
       "       [ 1.        , -1.44587789,  1.12773178, -1.70620856],\n",
       "       [ 1.        , -1.95714698, -0.01712356, -3.03870697],\n",
       "       ...,\n",
       "       [ 0.        ,  1.04734753,  2.4150367 ,  0.93479759],\n",
       "       [ 1.        , -1.92723879,  0.85583904, -1.32963721],\n",
       "       [ 1.        , -1.57584111,  1.37686666,  0.06045724]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = np.random.permutation(d.shape[0])\n",
    "d=d[df1]\n",
    "d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x,y, train_size= 0.8):\n",
    "    \n",
    "    X_train=d[0:int(train_size*x.shape[0]),1:4]\n",
    "    y_train=d[0:int(train_size*x.shape[0]),0]\n",
    "    X_test=d[int(train_size*x.shape[0]):,1:4]\n",
    "    y_test=d[int(train_size*x.shape[0]):,0]\n",
    "    return X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cr2Akm_A_FcJ",
    "outputId": "2b8f984d-f896-429f-8097-6fa9cba2d7dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 3) (800,) (200, 3) (200,)\n"
     ]
    }
   ],
   "source": [
    "X_train,  y_train,X_test, y_test= split_data(x,y, train_size= 0.8)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mu = np.zeros((x.shape[1]))\n",
    "# def covariance(x,mu):\n",
    "#     D, N = x.shape\n",
    "#     covariance = np.zeros((N, N))\n",
    "#     #mu = np.mean(x, axis=0)\n",
    "#     for i in range(N):\n",
    "#         for j in range(N):\n",
    "#             covariance[i,j]=(1/(D-1)*np.sum(x[:,i]*x[:,j]))-(D*mu[i]*mu[j])/(D-1)\n",
    "\n",
    "#     return covariance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    " def covariance(x, mu):\n",
    "    d = x.shape[1]\n",
    "    mu=np.mean(x,axis=0)\n",
    "    cov = np.zeros((d, d))\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            cov[i, j] = np.sum((x[:,i] - mu[i]) * (x[:,j] - mu[j])) / (len(x) - 1)\n",
    "    return cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.84495325, 0.02790646, 1.00137533],\n",
       "       [0.02790646, 1.00170721, 0.05539176],\n",
       "       [1.00137533, 0.05539176, 1.74832   ]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covariance(x,mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.84495325, 0.02790646, 1.00137533],\n",
       "       [0.02790646, 1.00170721, 0.05539176],\n",
       "       [1.00137533, 0.05539176, 1.74832   ]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(x,rowvar=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.498, 0.502])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi=np.zeros(2)\n",
    "for i in range(2):\n",
    "    phi[i]=np.mean(y==i)\n",
    "phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99515416,  1.04188282,  0.99941748],\n",
       "       [-1.01309105,  0.95696514, -0.93218425]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=np.zeros((2,3))\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        ko=np.where(y==i)\n",
    "        b=x[ko]\n",
    "        m[i,j]=np.mean(b[:,j].T)\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.012984932798671576"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(x[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDA:\n",
    "  def __init__(self):\n",
    "    ## set mu, phi and sigma to None\n",
    "    self.mu=None\n",
    "    self.phi=None\n",
    "    self.sigma=None\n",
    "    \n",
    "  def fit(self,x,y):\n",
    "    k=2 #np.unique(y).size  # Number of class.\n",
    "    d=x.shape[1] # input dim\n",
    "    m= x.shape[0]# Number of examples.\n",
    "    \n",
    "    ## Initialize mu, phi and sigma\n",
    "    self.mu= np.zeros((k,d))#: kxd, i.e., each row contains an individual class mu.\n",
    "    self.sigma= np.zeros((k,d,d))#: kxdxd, i.e., each row contains an individual class sigma.\n",
    "    self.phi= np.zeros((k))# d-dimension\n",
    "\n",
    "    ## START THE LEARNING: estimate mu, phi and sigma.\n",
    "    for lab in range(k):\n",
    "        \n",
    "        self.phi[lab] = np.sum(lab==y)/m \n",
    "        self.mu[lab] = np.mean(x[lab==y], axis =0)\n",
    "        self.sigma[lab] = covariance(x[lab==y], self.mu[lab])\n",
    "    return self.phi,self.mu, self.sigma\n",
    "            \n",
    "            \n",
    "\n",
    "  def predict_proba(self,x):\n",
    "    # reshape or flatt x.\n",
    "    #x= x.reshape(-1, self.mu.shape[1])\n",
    "    #x=x.reshape(-1,1)\n",
    "    #x=self.mu.shape[0]\n",
    "    d= x.shape[0]\n",
    "    #k_class = self.mu.shape[0] \n",
    "    k_class= self.mu.shape[0]  # Number of classes we have in our case it's k = 2\n",
    "    probabilities = np.zeros((d, k_class))\n",
    "    \n",
    "    ## START THE LEARNING: estimate mu, phi and sigma.\n",
    "    for lab in range(k_class):\n",
    "        det_cov= np.linalg.det(self.sigma[lab])\n",
    "        inv_cov=np.linalg.inv(self.sigma[lab])\n",
    "        for j in range(x.shape[0]):\n",
    "            first_term=1/((2*np.pi)**(d/2)*(det_cov**0.5))\n",
    "            #first_term=((1/(((2*np.pi)**(d/2))*(det_cov**0.5)))\n",
    "            exponential=-0.5*((x[j]-self.mu[lab]).T)@(inv_cov)@(x[j]-self.mu[lab])\n",
    "            second_term=np.exp(exponential)\n",
    "            probabilities[j, lab] = first_term*second_term*self.phi[lab]\n",
    "    return probabilities\n",
    "\n",
    "  def predict(self,x):\n",
    "    predict=self.predict_proba(x)\n",
    "    \n",
    "    y = np.argmax(predict,axis = 1)\n",
    "    #Predict = np.argmax(self.predict_proba(x))\n",
    "    return y\n",
    "    \n",
    "  \n",
    "  def accuracy(self, y, ypreds):\n",
    "#     ypred = self.predict(y)\n",
    "    result = np.mean(y == ypreds)\n",
    "    return result * 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "id": "l_qO0Yp1c3Is"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.49875, 0.50125]),\n",
       " array([[ 0.94944287,  1.0486899 ,  1.00393755],\n",
       "        [-1.02338324,  0.92544498, -0.91987664]]),\n",
       " array([[[ 0.90472612, -0.39514042, -0.05992127],\n",
       "         [-0.39514042,  1.73070546,  0.10004349],\n",
       "         [-0.05992127,  0.10004349,  0.03891138]],\n",
       " \n",
       "        [[ 0.80620946,  0.34220246,  0.11721226],\n",
       "         [ 0.34220246,  0.35338   , -0.07501384],\n",
       "         [ 0.11721226, -0.07501384,  1.65402195]]]))"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= GDA()\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_train[y_train==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 3)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "id": "NKY1eojY1l4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.08027739e-109, 1.48333261e-080],\n",
       "       [9.79548417e-240, 9.79722059e-082],\n",
       "       [7.26116871e-081, 1.73380495e-084],\n",
       "       [2.64153169e-080, 1.63860676e-081],\n",
       "       [1.15547923e-093, 8.00344593e-081],\n",
       "       [6.16375546e-081, 3.90667607e-083],\n",
       "       [9.91895325e-105, 4.56432160e-081],\n",
       "       [5.93897967e-081, 6.06130537e-089],\n",
       "       [2.13047162e-081, 4.15288945e-098],\n",
       "       [3.53364554e-086, 4.74772557e-081],\n",
       "       [3.55238101e-139, 6.64023086e-081],\n",
       "       [1.06248058e-147, 1.92952038e-081],\n",
       "       [1.15207539e-081, 1.24440590e-083],\n",
       "       [2.92463641e-080, 5.10421540e-082],\n",
       "       [2.13927271e-080, 1.27506183e-081],\n",
       "       [2.73806147e-080, 3.25099066e-082],\n",
       "       [1.35884865e-095, 6.38301072e-081],\n",
       "       [3.25462190e-080, 4.26688692e-082],\n",
       "       [1.64265467e-080, 7.63542739e-088],\n",
       "       [1.69864750e-103, 9.54964576e-081],\n",
       "       [1.78894161e-196, 5.79675819e-082],\n",
       "       [1.01144796e-080, 4.61654926e-087],\n",
       "       [2.69875626e-081, 5.35054949e-081],\n",
       "       [2.95935135e-158, 6.33259211e-081],\n",
       "       [4.42681961e-081, 3.95697687e-084],\n",
       "       [5.85608227e-093, 1.21948143e-080],\n",
       "       [4.76953080e-113, 1.21749777e-081],\n",
       "       [1.79647416e-080, 5.84417831e-085],\n",
       "       [1.14577619e-135, 3.33835459e-081],\n",
       "       [9.03605330e-126, 4.75947451e-081],\n",
       "       [2.57142189e-080, 1.14421803e-082],\n",
       "       [3.61383171e-181, 5.32790591e-081],\n",
       "       [8.56216271e-158, 6.39466466e-081],\n",
       "       [8.21690406e-105, 6.80043830e-081],\n",
       "       [1.19764183e-104, 3.19347485e-081],\n",
       "       [5.42678085e-081, 5.01778079e-081],\n",
       "       [1.02770502e-091, 4.78272390e-082],\n",
       "       [1.80365319e-080, 2.18066617e-082],\n",
       "       [3.83999932e-243, 5.47364492e-082],\n",
       "       [9.75388802e-090, 2.07407213e-081],\n",
       "       [7.20775230e-093, 2.70538236e-081],\n",
       "       [6.40228337e-098, 1.35365268e-080],\n",
       "       [1.51796118e-082, 3.77399127e-081],\n",
       "       [1.49365387e-151, 6.11606111e-081],\n",
       "       [1.20185570e-104, 9.69322414e-081],\n",
       "       [2.75862152e-080, 1.70067866e-082],\n",
       "       [2.06210242e-080, 1.19973675e-082],\n",
       "       [2.11094612e-080, 5.00831452e-083],\n",
       "       [1.10865917e-080, 3.54524966e-086],\n",
       "       [1.37905039e-081, 4.10371423e-084],\n",
       "       [2.29584470e-080, 2.67006922e-082],\n",
       "       [5.92124891e-145, 4.65147355e-081],\n",
       "       [4.91410599e-133, 9.96111664e-082],\n",
       "       [1.27683173e-080, 2.58006650e-086],\n",
       "       [7.67652004e-193, 2.25691599e-081],\n",
       "       [1.84993231e-080, 1.35641546e-081],\n",
       "       [7.04930789e-081, 3.35034577e-086],\n",
       "       [4.34315780e-172, 3.55569323e-081],\n",
       "       [7.57336011e-129, 1.10404853e-080],\n",
       "       [2.41433461e-091, 1.14056122e-080],\n",
       "       [1.39667123e-080, 4.13451700e-088],\n",
       "       [3.23568142e-099, 1.05993400e-080],\n",
       "       [7.89469022e-105, 2.71071205e-081],\n",
       "       [1.62706153e-080, 3.37131249e-082],\n",
       "       [5.32274799e-131, 4.81176021e-082],\n",
       "       [2.38057201e-080, 1.90850502e-086],\n",
       "       [2.41206412e-080, 3.77966140e-084],\n",
       "       [9.37995738e-172, 1.13609088e-081],\n",
       "       [1.27606097e-080, 1.44751230e-082],\n",
       "       [5.36313687e-081, 1.71375564e-087],\n",
       "       [1.40169772e-080, 2.88080120e-083],\n",
       "       [1.24592652e-122, 4.97768397e-081],\n",
       "       [1.22281882e-081, 4.54616660e-081],\n",
       "       [2.32003125e-167, 3.44849003e-081],\n",
       "       [6.93014654e-116, 3.74224830e-081],\n",
       "       [8.47948553e-081, 1.34683376e-083],\n",
       "       [2.22875933e-184, 3.84454029e-081],\n",
       "       [2.24142599e-124, 1.59065678e-081],\n",
       "       [1.87038652e-081, 3.46538922e-091],\n",
       "       [1.41439491e-088, 8.91363634e-082],\n",
       "       [1.21719254e-080, 2.92784749e-082],\n",
       "       [9.59279273e-081, 3.74622934e-083],\n",
       "       [2.87208618e-117, 4.10941422e-081],\n",
       "       [2.04751437e-082, 5.29414824e-081],\n",
       "       [1.24386825e-080, 6.11238399e-083],\n",
       "       [1.34738282e-080, 1.58397288e-086],\n",
       "       [3.94477044e-081, 4.52312807e-083],\n",
       "       [6.10865894e-113, 3.16263017e-081],\n",
       "       [4.31602395e-082, 8.89737097e-112],\n",
       "       [8.34491048e-081, 1.70582988e-083],\n",
       "       [1.39246789e-080, 1.21645102e-082],\n",
       "       [2.28757673e-080, 1.17824963e-082],\n",
       "       [1.25840167e-168, 1.42383073e-081],\n",
       "       [1.63319557e-080, 2.40619443e-081],\n",
       "       [2.91953722e-080, 4.98267254e-085],\n",
       "       [1.53066911e-086, 6.88511732e-081],\n",
       "       [1.34890375e-096, 8.21472044e-081],\n",
       "       [1.43230890e-080, 2.62480583e-085],\n",
       "       [1.90741113e-107, 9.12786663e-081],\n",
       "       [1.27949262e-135, 1.88448858e-081],\n",
       "       [5.70506328e-081, 4.03892300e-087],\n",
       "       [6.75433261e-115, 3.31067797e-081],\n",
       "       [9.26877742e-127, 1.33641598e-080],\n",
       "       [2.08401846e-080, 1.18960023e-086],\n",
       "       [2.03666951e-143, 6.24121760e-081],\n",
       "       [8.91421763e-094, 5.26167979e-081],\n",
       "       [4.82067113e-083, 5.70596854e-081],\n",
       "       [9.43909189e-095, 9.28072227e-081],\n",
       "       [1.18808336e-154, 6.17839502e-081],\n",
       "       [8.56445852e-081, 1.51377322e-084],\n",
       "       [1.69250431e-117, 5.91731113e-081],\n",
       "       [3.13949160e-082, 6.31947330e-082],\n",
       "       [1.30643172e-080, 3.90637653e-082],\n",
       "       [2.08174443e-080, 7.02868814e-087],\n",
       "       [1.13348876e-080, 2.67852225e-090],\n",
       "       [3.80799889e-112, 5.42591384e-081],\n",
       "       [7.66681584e-105, 3.66042938e-081],\n",
       "       [4.29530968e-104, 9.72209586e-081],\n",
       "       [2.81122397e-080, 3.98889472e-083],\n",
       "       [1.37387187e-094, 6.33574976e-081],\n",
       "       [2.96864821e-081, 4.35310065e-085],\n",
       "       [1.02356147e-147, 6.92212030e-081],\n",
       "       [1.40333498e-080, 3.76593322e-089],\n",
       "       [1.84082252e-080, 1.33876319e-082],\n",
       "       [1.94022302e-091, 6.93974473e-081],\n",
       "       [3.92890461e-115, 7.88809604e-081],\n",
       "       [9.49857479e-081, 8.51389305e-084],\n",
       "       [7.07553085e-204, 1.16911345e-081],\n",
       "       [1.52273844e-080, 7.44215031e-082],\n",
       "       [1.43380768e-080, 1.07355433e-083],\n",
       "       [1.51257346e-080, 3.84360161e-082],\n",
       "       [9.04333218e-081, 7.32082727e-089],\n",
       "       [1.71803560e-080, 2.37576852e-086],\n",
       "       [1.34154748e-080, 1.56090057e-082],\n",
       "       [2.97989262e-080, 2.55053176e-083],\n",
       "       [3.65707882e-081, 1.34342490e-083],\n",
       "       [3.78213218e-093, 1.11658278e-080],\n",
       "       [7.07252141e-094, 8.50470596e-081],\n",
       "       [1.16053369e-080, 2.26681293e-087],\n",
       "       [1.00689547e-106, 1.00628440e-080],\n",
       "       [1.00497221e-136, 4.70982974e-081],\n",
       "       [1.62465877e-080, 1.61190848e-086],\n",
       "       [8.12280681e-203, 2.75819235e-081],\n",
       "       [2.04518917e-080, 1.31363234e-084],\n",
       "       [4.50789931e-222, 8.04775665e-082],\n",
       "       [5.14308585e-081, 1.56101377e-082],\n",
       "       [4.52141592e-104, 1.08074023e-080],\n",
       "       [2.63321920e-081, 4.06070957e-086],\n",
       "       [2.02057720e-080, 1.99734667e-086],\n",
       "       [1.93956238e-080, 1.34913930e-081],\n",
       "       [1.28852417e-080, 9.45478803e-082],\n",
       "       [3.18638014e-089, 1.24533954e-081],\n",
       "       [1.39152439e-086, 9.15940991e-081],\n",
       "       [1.24592534e-081, 1.99247784e-084],\n",
       "       [9.48647788e-081, 1.68578622e-089],\n",
       "       [1.25211331e-115, 9.78061632e-081],\n",
       "       [1.53010431e-085, 7.14159764e-081],\n",
       "       [1.33444882e-080, 3.01955293e-083],\n",
       "       [6.19355138e-081, 3.24791728e-088],\n",
       "       [1.25817001e-092, 8.52943249e-081],\n",
       "       [1.30531258e-080, 7.00862339e-082],\n",
       "       [2.78197360e-080, 8.38697726e-084],\n",
       "       [1.74098686e-080, 1.52321268e-087],\n",
       "       [6.66079545e-083, 1.32412620e-081],\n",
       "       [1.28446051e-101, 5.26643990e-081],\n",
       "       [2.84335614e-080, 1.70405239e-084],\n",
       "       [1.01110855e-080, 3.05386317e-087],\n",
       "       [1.36777550e-080, 9.81203301e-087],\n",
       "       [1.10901760e-112, 9.41207643e-081],\n",
       "       [3.06035118e-080, 4.40699996e-082],\n",
       "       [1.32774108e-156, 7.31241419e-081],\n",
       "       [3.74701276e-101, 8.75222907e-081],\n",
       "       [2.26834299e-110, 2.04630870e-081],\n",
       "       [1.21802409e-081, 3.78578543e-090],\n",
       "       [1.59128451e-081, 2.87712606e-082],\n",
       "       [6.64446575e-084, 6.49561589e-081],\n",
       "       [1.09832569e-080, 1.08616831e-083],\n",
       "       [2.19488021e-109, 6.97866813e-083],\n",
       "       [5.36627026e-179, 2.94763852e-081],\n",
       "       [6.56782976e-092, 6.93499570e-081],\n",
       "       [8.91595672e-081, 2.40387666e-085],\n",
       "       [1.58159152e-092, 8.55906126e-081],\n",
       "       [1.07392822e-080, 4.53680380e-083],\n",
       "       [1.00943816e-080, 6.94274576e-089],\n",
       "       [6.05211353e-081, 9.94407915e-082],\n",
       "       [2.98368129e-080, 1.65099698e-082],\n",
       "       [1.67082422e-080, 1.57804366e-082],\n",
       "       [7.51820859e-122, 1.21422392e-080],\n",
       "       [9.72113942e-095, 1.42032317e-081],\n",
       "       [9.47486629e-081, 1.33073848e-082],\n",
       "       [7.29853762e-081, 1.32666141e-084],\n",
       "       [2.37114443e-135, 1.15785914e-080],\n",
       "       [2.51874955e-106, 4.70838530e-081],\n",
       "       [1.50214653e-080, 1.27080957e-082],\n",
       "       [5.89700091e-081, 8.18448254e-086],\n",
       "       [1.68599994e-081, 4.22349324e-083],\n",
       "       [3.02350516e-080, 1.05023512e-084],\n",
       "       [1.45148502e-080, 1.30793440e-082],\n",
       "       [4.34394514e-124, 7.05901656e-081],\n",
       "       [9.45529071e-090, 1.98891674e-081]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yproba= model.predict_proba(X_test)\n",
    "yproba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "id": "D4clV6PK1UJK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypreds= model.predict(X_test)\n",
    "ypreds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "id": "QgG1xPUg1ULw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.0"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.accuracy(y_test, ypreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "id": "OpXYY-yj1UOj"
   },
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "  '''\n",
    "  The goal of this class is to create a LogisticRegression class, \n",
    "  that we will use as our model to classify data point into a corresponding class\n",
    "  '''\n",
    "  def __init__(self,lr,n_epochs):\n",
    "    self.lr = lr\n",
    "    self.n_epochs = n_epochs\n",
    "    self.train_losses = []\n",
    "    self.w = None\n",
    "    self.weight = []\n",
    "\n",
    "  def add_ones(self, x):\n",
    "    ##### WRITE YOUR CODE HERE #####\n",
    "    one = np.ones((x.shape[0],1))\n",
    "    return np.hstack((one,x))\n",
    "    #### END CODE ####\n",
    "\n",
    "  def sigmoid(self, x):\n",
    "    return 1/(1+np.exp(-x@self.w))\n",
    "\n",
    "\n",
    "  def cross_entropy(self, x, y_true):\n",
    "    ##### WRITE YOUR CODE HERE #####\n",
    "    y_pred = self.sigmoid(x)\n",
    "    loss = -np.mean(y_true*np.log(y_pred)+(1-y_true)*np.log(1-y_pred))\n",
    "    return loss\n",
    "    #### END CODE ####\n",
    "  \n",
    "  def predict_proba(self,x):  #This function will use the sigmoid function to compute the probalities\n",
    "    ##### WRITE YOUR CODE HERE #####\n",
    "    x= self.add_ones(x)\n",
    "    proba = self.sigmoid(x)\n",
    "    return proba\n",
    "    #### END CODE ####\n",
    "\n",
    "  def predict(self,x):\n",
    "    ##### WRITE YOUR CODE HERE #####\n",
    "    probas = self.predict_proba(x)\n",
    "    output = [0 if p<0.5 else 1 for p in probas]#np.where(probas>=0.5, 1, 0)      #convert the probalities into 0 and 1 by using a treshold=0.5\n",
    "    return output\n",
    "    #### END CODE ####\n",
    "\n",
    "  def fit(self,x,y):\n",
    "    # Add ones to x\n",
    "    x=self.add_ones(x)\n",
    "\n",
    "    # reshape y if needed\n",
    "    y=y.reshape(-1,1)\n",
    "\n",
    "    # Initialize w to zeros vector >>> (x.shape[1])\n",
    "    self.w=np.zeros((x.shape[1],1))\n",
    "\n",
    "    for epoch in range(self.n_epochs):\n",
    "      # make predictions\n",
    "      ypred = self.sigmoid(x)\n",
    "\n",
    "      #compute the gradient\n",
    "      dl = (-1/x.shape[0])*(x.T@(y-ypred))\n",
    "\n",
    "      #update rule\n",
    "      self.w=self.w-self.lr*dl\n",
    "\n",
    "      #Compute and append the training loss in a list\n",
    "      loss = self.cross_entropy(x,y)\n",
    "      self.train_losses.append(loss)\n",
    "\n",
    "      if epoch%1000 == 0:\n",
    "        print(f'loss for epoch {epoch}  : {loss}')\n",
    "\n",
    "  def accuracy(self,y_true, y_pred):\n",
    "    ##### WRITE YOUR CODE HERE #####\n",
    "    acc = np.mean(y_true==y_pred)*100\n",
    "    return acc\n",
    "    #### END CODE ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "id": "8cvRcUO2rtKo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch 0  : 0.688409308099198\n"
     ]
    }
   ],
   "source": [
    "model =LogisticRegression(lr=0.01,n_epochs=1000)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is: 94.625\n",
      " \n",
      "The test accuracy is: 96.0\n"
     ]
    }
   ],
   "source": [
    "ypred_train = model.predict(X_train)\n",
    "acc = model.accuracy(y_train,ypred_train)\n",
    "print(f\"The training accuracy is: {acc}\")\n",
    "print(\" \")\n",
    "\n",
    "ypred_test = model.predict(X_test)\n",
    "acc = model.accuracy(y_test,ypred_test)\n",
    "print(f\"The test accuracy is: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
